{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cca30dfe-50ee-4fa7-9dd3-bee9a761c78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker.huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c71b2bbb-636f-4ce3-baf0-d951e989a36a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::707684582322:role/service-role/AmazonSageMaker-ExecutionRole-20191024T163188\n",
      "sagemaker bucket: sagemaker-eu-west-1-707684582322\n",
      "sagemaker session region: eu-west-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0789553-9676-40e2-a15b-0558bb19b188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-707684582322/huggingface-finetune-twitter2023-03-16--2023-03-16-01-39-16-251/output/model.tar.gz'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "training_job_name = \"huggingface-finetune-twitter2023-03-16--2023-03-16-01-39-16-251\"\n",
    "s3_model_location = 's3://{}/{}/output/model.tar.gz'.format(sagemaker_session_bucket, training_job_name)\n",
    "s3_model_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84c201ba-19eb-42bb-aeb6-a91b1d06b84d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dataset, DataLoader, random_split\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoTokenizer, AutoModel, AutoConfig\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datetime\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoTokenizer, AutoModel\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "TOKENIZER_MODEL = \u001b[33m\"\u001b[39;49;00m\u001b[33mbert-base-multilingual-uncased\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "device = \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "pretrained_model = \u001b[33m\"\u001b[39;49;00m\u001b[33mbert-base-multilingual-uncased\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# PyTorch models inherit from torch.nn.Module\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mSentenceMultiClassClassifier\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,number_class, pretrained_model):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(SentenceMultiClassClassifier, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.number_class = number_class\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#self.pretrained = AutoModel.from_pretrained(pretrained_model).to(device)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.pretrained = AutoModel.from_pretrained(pretrained_model,config=AutoConfig.from_pretrained(pretrained_model, output_attentions=\u001b[34mTrue\u001b[39;49;00m,output_hidden_states=\u001b[34mTrue\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#self.dropout = nn.Dropout(0.5) \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#self.fc1 = nn.Linear(768, 1200)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#self.fc2 = nn.Linear(1200, 1400)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#self.fc3 = nn.Linear(1400, number_class)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.linear = nn.Linear(\u001b[34m768\u001b[39;49;00m, number_class)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.layeroutput = torch.nn.Sigmoid()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_ids, token_type_ids, attention_mask):            \u001b[37m\u001b[39;49;00m\n",
      "        output_pretrained = \u001b[36mself\u001b[39;49;00m.pretrained(input_ids, token_type_ids, attention_mask)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Freeze the BERT parameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.pretrained.parameters():\u001b[37m\u001b[39;49;00m\n",
      "            param.requires_grad = \u001b[34mFalse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#x = F.relu(self.fc1(output_pretrained.last_hidden_state[:,0,:].view(-1,768)))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#x = self.dropout(x)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#x = F.relu(self.fc2(x))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#x = self.dropout(x)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        x = output_pretrained.last_hidden_state[:,\u001b[34m0\u001b[39;49;00m,:].view(-\u001b[34m1\u001b[39;49;00m,\u001b[34m768\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.linear(x)\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.layeroutput(x)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m x\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):   \u001b[37m\u001b[39;49;00m\n",
      "    NUM_CLASS = \u001b[34m11\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_MODEL)\u001b[37m\u001b[39;49;00m\n",
      "    model = SentenceMultiClassClassifier(NUM_CLASS,TOKENIZER_MODEL)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#model = torch.jit.load(f)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        model.load_state_dict(torch.load(f))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model.eval()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device), tokenizer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(text, model_and_tokenizer):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# destruct model and tokenizer\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model, tokenizer = model_and_tokenizer    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Tokenize sentences\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_text = tokenizer(text, max_length = \u001b[34m128\u001b[39;49;00m, padding=\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, return_tensors=\u001b[33m\"\u001b[39;49;00m\u001b[33mpt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_text[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = tokenized_text[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].to(device)\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_text[\u001b[33m'\u001b[39;49;00m\u001b[33mtoken_type_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = tokenized_text[\u001b[33m'\u001b[39;49;00m\u001b[33mtoken_type_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].to(device)\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_text[\u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = tokenized_text[\u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Compute token embeddings\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "        model_output = model(**tokenized_text)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# return dictonary, which will be json serializable\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model_output.tolist()\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./scripts/inference_nlp_bert_sm_compatible.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee8210b2-bc51-4801-bfe0-167c01017ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g4dn.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab9cc686-d54a-46e2-a0d3-e45a2878005d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-707684582322/huggingface-finetune-twitter2023-03-16--2023-03-16-01-39-16-251/output/model.tar.gz'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_model_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4722d8b4-89a3-464e-b766-43174719d9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_location, # path to your model and script\n",
    "   entry_point=\"./scripts/inference_nlp_bert_sm_compatible.py\",\n",
    "   source_dir = './scripts',\n",
    "   role=role,\n",
    "   transformers_version=\"4.6\",  # transformers version used\n",
    "   pytorch_version=\"1.7\",        # pytorch version used\n",
    "   py_version='py36',            # python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02756223-6090-4db0-a91a-5b3a108e51be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df5acb-7131-4a1c-b57c-e6c68db1a7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f33fe110-a039-4e8d-add1-f26184e66194",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(\"I am so happy about this situation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d547e3a3-ffcf-4758-938e-00b2a635018f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.24477840960025787,\n",
       "  0.13813115656375885,\n",
       "  0.25555047392845154,\n",
       "  0.17213194072246552,\n",
       "  0.4122581481933594,\n",
       "  0.11252996325492859,\n",
       "  0.3421306908130646,\n",
       "  0.151715949177742,\n",
       "  0.33474868535995483,\n",
       "  0.0483432300388813,\n",
       "  0.052165474742650986]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f2c79ba-107d-4df0-a01c-6b20f9dbdf40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b3d89-9475-4ec8-8658-690866c15156",
   "metadata": {},
   "source": [
    "## Inference with SDK Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5397fb4-4063-4de8-9d74-62131a93105b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f41e5d20-6535-4f1e-9254-1462897a1aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9754dd27-f610-4976-a7c9-67d7b9dde684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"huggingface-pytorch-inference-2023-03-16-06-10-43-495\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "194212c7-0f8b-40ad-9f83-bf530d94cfdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_json = \"I am so happy about this situation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4f010a6-1692-4bb3-a630-9fc138b0d296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_with_endpoint(endpoint_name,runtime,text):\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(input_json),\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    results = response[\"Body\"].read()\n",
    "    return json.loads(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aaafac9b-9339-4ca4-972d-2f96766eed45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24477840960025787, 0.13813115656375885, 0.25555047392845154, 0.17213194072246552, 0.4122581481933594, 0.11252996325492859, 0.3421306908130646, 0.151715949177742, 0.33474868535995483, 0.0483432300388813, 0.052165474742650986]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_with_endpoint(endpoint_name, runtime, input_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7267cf7-035c-4bee-a28f-9bf93b1cb81b",
   "metadata": {},
   "source": [
    "## Evaluation on twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a74029c2-4d15-47e3-912f-fce7281f3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a0146dc-1583-45f7-84b3-ce2a5f55799d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/sem_eval_2018_task_1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ebf6bda1-de02-4ed7-b2c7-34845d89a827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'anger',\n",
       " 1: 'anticipation',\n",
       " 2: 'disgust',\n",
       " 3: 'fear',\n",
       " 4: 'joy',\n",
       " 5: 'love',\n",
       " 6: 'optimism',\n",
       " 7: 'pessimism',\n",
       " 8: 'sadness',\n",
       " 9: 'surprise',\n",
       " 10: 'trust'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name = [label for label in df.columns if label not in ['ID', 'Tweet']]\n",
    "id2label = {idx:label for idx, label in enumerate(label_name)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb7fe957-ad7a-430e-8827-8798751cd95f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  love  optimism  pessimism  \\\n",
       "0      1             1        0     0    0     0         1          0   \n",
       "1      0             0        1     0    0     0         0          0   \n",
       "2      1             0        1     0    0     0         0          0   \n",
       "3      0             0        0     0    1     0         0          0   \n",
       "4      0             0        0     1    0     0         0          0   \n",
       "\n",
       "   sadness  surprise  trust  \n",
       "0        0         0      1  \n",
       "1        0         0      0  \n",
       "2        1         0      0  \n",
       "3        1         0      0  \n",
       "4        1         0      0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index = df.iloc[:,2:].astype(int)\n",
    "label_index.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c4484bcb-6010-45c3-9021-cf9b51c77885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_tweet = df.loc[:,[\"Tweet\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a364698-f935-45de-a9b1-dd334f02f0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Adnan__786__ @AsYouNotWish Dont worry Indian army is on its ways to dispatch all Terrorists to Hell']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "33f25d57-2dd4-40b7-b533-ba8214eba474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.24477840960025787,\n",
       "  0.13813115656375885,\n",
       "  0.25555047392845154,\n",
       "  0.17213194072246552,\n",
       "  0.4122581481933594,\n",
       "  0.11252996325492859,\n",
       "  0.3421306908130646,\n",
       "  0.151715949177742,\n",
       "  0.33474868535995483,\n",
       "  0.0483432300388813,\n",
       "  0.052165474742650986]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = prediction_with_endpoint(endpoint_name, runtime, text_tweet[0])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "047689df-fecd-476f-8a09-fb377e963546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def proba_to_label(prediction_proba,id2label,threshold):\n",
    "    prediction_label = []\n",
    "    for index in range(len(prediction_proba)):\n",
    "        if prediction_proba[index] > threshold:\n",
    "            prediction_label.append(id2label[index])\n",
    "            \n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e9d03e6-2ee4-42f7-8165-dbe3708c9ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy', 'optimism', 'sadness']\n"
     ]
    }
   ],
   "source": [
    "print(proba_to_label(results[0],id2label,0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88bc5f8-acf7-4a23-8910-5623e5b4393c",
   "metadata": {},
   "source": [
    "### Prediction over entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "400349a8-6372-437c-8398-fc5d93050f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_proba = np.zeros_like(label_index,dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9151f6-5beb-4c0e-8905-78b866de5c46",
   "metadata": {},
   "source": [
    "#### real-time endpoints that make one prediction at a time, over http "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c25f96b-0798-4fa8-ba38-fed722968c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in range(len(text_tweet)):\n",
    "    result = prediction_with_endpoint(endpoint_name, runtime, text_tweet[index])\n",
    "    result = np.squeeze(np.array(result), axis=0)    \n",
    "    predictions_proba[index,:] = result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4bc851db-06e8-44ad-a3f9-bb6cf056dc38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1582d021-f677-4804-8cda-33c1ecd98782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_label_metrics(labels, predictions_proba, threshold = 0.5):\n",
    "    y_true = labels\n",
    "\n",
    "    predictions = np.zeros_like(labels)\n",
    "    predictions[np.where(predictions_proba >= threshold)] = 1\n",
    "    \n",
    "    y_pred = predictions\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    f1_micro_average = f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    metrics = {'precision': precision,\n",
    "               'recall': recall,\n",
    "               'f1': f1_micro_average}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e36d06c8-545f-4200-8d66-f21988e6b51d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = multi_label_metrics(label_index, predictions_proba, threshold = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1e8b860-3edb-4609-b3e7-c6747620e832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.3625856602229723,\n",
       " 'recall': 0.4505019697547338,\n",
       " 'f1': 0.4017907741131134}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e461db25-87a1-4cb1-81b3-6cabdaea9e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
