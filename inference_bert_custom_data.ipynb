{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50a923-c5c8-42bf-9e80-481fafaee13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/training\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2959305-3f91-4bbb-af81-78e70f1651e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86b536-6976-416f-b255-1e4dbd9c5036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch models inherit from torch.nn.Module\n",
    "class SentenceMultiClassClassifier(nn.Module):\n",
    "    def __init__(self,number_class, pretrained_model):\n",
    "        super(SentenceMultiClassClassifier, self).__init__()\n",
    "        self.number_class = number_class\n",
    "        #self.pretrained = AutoModel.from_pretrained(pretrained_model).to(device)\n",
    "        self.pretrained = AutoModel.from_pretrained(pretrained_model,config=AutoConfig.from_pretrained(pretrained_model, output_attentions=True,output_hidden_states=True))\n",
    "\n",
    "        #self.dropout = nn.Dropout(0.5) \n",
    "        #self.fc1 = nn.Linear(768, 1200)\n",
    "        #self.fc2 = nn.Linear(1200, 1400)\n",
    "        #self.fc3 = nn.Linear(1400, number_class)\n",
    "        \n",
    "        self.linear = nn.Linear(768, number_class)\n",
    "        self.layeroutput = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):            \n",
    "        output_pretrained = self.pretrained(input_ids, token_type_ids, attention_mask)\n",
    "        # Freeze the BERT parameters\n",
    "        for param in self.pretrained.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        #x = F.relu(self.fc1(output_pretrained.last_hidden_state[:,0,:].view(-1,768)))\n",
    "        #x = self.dropout(x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = output_pretrained.last_hidden_state[:,0,:].view(-1,768)\n",
    "        x = self.linear(x)\n",
    "        x = self.layeroutput(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dddce-0c6d-441d-a81c-0bbd071dc50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKENIZER_MODEL = \"bert-base-multilingual-uncased\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pretrained_model = \"bert-base-multilingual-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7059fc1-9f96-4536-a33a-f040e21ef780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_fn(model_dir):   \n",
    "    NUM_CLASS = 11\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_MODEL)\n",
    "    model = SentenceMultiClassClassifier(NUM_CLASS,TOKENIZER_MODEL)\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        #model = torch.jit.load(f)\n",
    "        model.load_state_dict(torch.load(f))\n",
    "\n",
    "    model.eval()\n",
    "    return model.to(device), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fb68d-ba5c-41a3-85fe-10b415ea0318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_fn(text, model_and_tokenizer):\n",
    "    # destruct model and tokenizer\n",
    "    model, tokenizer = model_and_tokenizer    \n",
    "    \n",
    "    # Tokenize sentences\n",
    "    tokenized_text = tokenizer(text, max_length = 128, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    tokenized_text['input_ids'] = tokenized_text['input_ids'].to(device)\n",
    "    tokenized_text['token_type_ids'] = tokenized_text['token_type_ids'].to(device)\n",
    "    tokenized_text['attention_mask'] = tokenized_text['attention_mask'].to(device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**tokenized_text)\n",
    "\n",
    "    # return dictonary, which will be json serializable\n",
    "    return model_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847d705-04a8-4403-b27d-d2afc6369c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_and_tokenizer = model_fn(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a7f20-2af1-4a4f-aa28-01809cf003c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"I am so happy about this situation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf4f6c-73ed-48e8-88d7-0c909cfbc9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = predict_fn(text, model_and_tokenizer)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b143ea8-e008-4c67-b97a-6b2099c13814",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197917d-c7af-4489-9f92-bfdb70fc94ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff1f21-eea1-4e33-ba6b-382162f1e4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/sem_eval_2018_task_1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf550da0-ab31-4ab8-b6af-7e91e106b6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fddb57-a2fd-4c5d-83bf-e2da0b41b873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_name = [label for label in df.columns if label not in ['ID', 'Tweet']]\n",
    "id2label = {idx:label for idx, label in enumerate(label_name)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c9e19-e257-4905-ab1c-d62a91eb2167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_tweet = df.loc[:,[\"Tweet\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933176b-f1ad-43b0-b5a6-a97d36ae91e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861f6de-4ab1-4eb2-bb0a-5a56a4ec5e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = predict_fn(text_tweet[0], model_and_tokenizer)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9f5f7-e86a-482e-bc18-24204fa6c2b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def proba_to_label(prediction_proba,id2label,threshold):\n",
    "    prediction_label = []\n",
    "    for index in range(len(prediction_proba)):\n",
    "        if prediction_proba[index] > threshold:\n",
    "            prediction_label.append(id2label[index])\n",
    "            \n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a5792-a755-4652-89a7-9b2e86272b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(proba_to_label(results[0],id2label,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b9c0e-6cce-4f07-ae2e-26a73c5a8426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_index = df.iloc[:,2:].astype(int)\n",
    "label_index.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc29a9a-4a29-48aa-8a72-ca2dd3de3f62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_index = label_index.to_numpy()\n",
    "label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b94aa-1547-46c4-a3fc-d98abe791c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_proba = np.zeros_like(label_index,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d264945-80c3-4599-ba2b-b500e46a9d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in range(len(text_tweet)):\n",
    "    result = predict_fn(text_tweet[index], model_and_tokenizer)\n",
    "    result = np.squeeze(np.array(result), axis=0)    \n",
    "    predictions_proba[index,:] = result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976aef1-4380-4de8-8b84-9cff0f17ebdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eceeaf0-bcba-472d-84df-af443c700a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a710f-3823-4909-84be-ca149dbd7ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_label_metrics(labels, predictions_proba, threshold = 0.5):\n",
    "    y_true = labels\n",
    "\n",
    "    predictions = np.zeros_like(labels)\n",
    "    predictions[np.where(predictions_proba >= threshold)] = 1\n",
    "    \n",
    "    y_pred = predictions\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    f1_micro_average = f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    metrics = {'precision': precision,\n",
    "               'recall': recall,\n",
    "               'f1': f1_micro_average}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1013a-7ee3-4a85-b286-77059c34ea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = multi_label_metrics(label_index, predictions_proba, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ebf7d7-3380-453f-b3de-63ee116053ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde73d69-6e1f-4b5b-b51a-fea8b8f0c00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
