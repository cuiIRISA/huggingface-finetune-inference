{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9a50a923-c5c8-42bf-9e80-481fafaee13c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (4.26.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (4.63.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/training\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d2959305-3f91-4bbb-af81-78e70f1651e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1f86b536-6976-416f-b255-1e4dbd9c5036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch models inherit from torch.nn.Module\n",
    "class SentenceMultiClassClassifier(nn.Module):\n",
    "    def __init__(self,number_class, pretrained_model):\n",
    "        super(SentenceMultiClassClassifier, self).__init__()\n",
    "        self.number_class = number_class\n",
    "        #self.pretrained = AutoModel.from_pretrained(pretrained_model).to(device)\n",
    "        self.pretrained = AutoModel.from_pretrained(pretrained_model,config=AutoConfig.from_pretrained(pretrained_model, output_attentions=True,output_hidden_states=True))\n",
    "\n",
    "        #self.dropout = nn.Dropout(0.5) \n",
    "        #self.fc1 = nn.Linear(768, 1200)\n",
    "        #self.fc2 = nn.Linear(1200, 1400)\n",
    "        #self.fc3 = nn.Linear(1400, number_class)\n",
    "        \n",
    "        self.linear = nn.Linear(768, number_class)\n",
    "        self.layeroutput = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):            \n",
    "        output_pretrained = self.pretrained(input_ids, token_type_ids, attention_mask)\n",
    "        # Freeze the BERT parameters\n",
    "        for param in self.pretrained.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        #x = F.relu(self.fc1(output_pretrained.last_hidden_state[:,0,:].view(-1,768)))\n",
    "        #x = self.dropout(x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = output_pretrained.last_hidden_state[:,0,:].view(-1,768)\n",
    "        x = self.linear(x)\n",
    "        x = self.layeroutput(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6c1dddce-0c6d-441d-a81c-0bbd071dc50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKENIZER_MODEL = \"bert-base-multilingual-uncased\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pretrained_model = \"bert-base-multilingual-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c7059fc1-9f96-4536-a33a-f040e21ef780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_fn(model_dir):   \n",
    "    NUM_CLASS = 11\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_MODEL)\n",
    "    model = SentenceMultiClassClassifier(NUM_CLASS,TOKENIZER_MODEL)\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        #model = torch.jit.load(f)\n",
    "        model.load_state_dict(torch.load(f))\n",
    "\n",
    "    model.eval()\n",
    "    return model.to(device), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "088fb68d-ba5c-41a3-85fe-10b415ea0318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_fn(text, model_and_tokenizer):\n",
    "    # destruct model and tokenizer\n",
    "    model, tokenizer = model_and_tokenizer    \n",
    "    \n",
    "    # Tokenize sentences\n",
    "    tokenized_text = tokenizer(text, max_length = 128, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    tokenized_text['input_ids'] = tokenized_text['input_ids'].to(device)\n",
    "    tokenized_text['token_type_ids'] = tokenized_text['token_type_ids'].to(device)\n",
    "    tokenized_text['attention_mask'] = tokenized_text['attention_mask'].to(device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**tokenized_text)\n",
    "\n",
    "    # return dictonary, which will be json serializable\n",
    "    return model_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e847d705-04a8-4403-b27d-d2afc6369c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_and_tokenizer = model_fn(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e88a7f20-2af1-4a4f-aa28-01809cf003c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"I am so happy about this situation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7ecf4f6c-73ed-48e8-88d7-0c909cfbc9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.38515618443489075,\n",
       "  0.08222470432519913,\n",
       "  0.30914536118507385,\n",
       "  0.11874663084745407,\n",
       "  0.21496078372001648,\n",
       "  0.04816637188196182,\n",
       "  0.19921928644180298,\n",
       "  0.21099203824996948,\n",
       "  0.343722939491272,\n",
       "  0.018559658899903297,\n",
       "  0.014233306050300598]]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = predict_fn(text, model_and_tokenizer)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b143ea8-e008-4c67-b97a-6b2099c13814",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4197917d-c7af-4489-9f92-bfdb70fc94ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "30ff1f21-eea1-4e33-ba6b-382162f1e4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/sem_eval_2018_task_1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cf550da0-ab31-4ab8-b6af-7e91e106b6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-En-01559</td>\n",
       "      <td>@Adnan__786__ @AsYouNotWish Dont worry Indian ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-En-03739</td>\n",
       "      <td>Academy of Sciences, eschews the normally sobe...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-En-00385</td>\n",
       "      <td>I blew that opportunity -__- #mad</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-En-03001</td>\n",
       "      <td>This time in 2 weeks I will be 30... ðŸ˜¥</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-En-01988</td>\n",
       "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  anger  \\\n",
       "0  2018-En-01559  @Adnan__786__ @AsYouNotWish Dont worry Indian ...   True   \n",
       "1  2018-En-03739  Academy of Sciences, eschews the normally sobe...  False   \n",
       "2  2018-En-00385                  I blew that opportunity -__- #mad   True   \n",
       "3  2018-En-03001             This time in 2 weeks I will be 30... ðŸ˜¥  False   \n",
       "4  2018-En-01988  #Deppression is real. Partners w/ #depressed p...  False   \n",
       "\n",
       "   anticipation  disgust   fear    joy   love  optimism  pessimism  sadness  \\\n",
       "0          True    False  False  False  False      True      False    False   \n",
       "1         False     True  False  False  False     False      False    False   \n",
       "2         False     True  False  False  False     False      False     True   \n",
       "3         False    False  False   True  False     False      False     True   \n",
       "4         False    False   True  False  False     False      False     True   \n",
       "\n",
       "   surprise  trust  \n",
       "0     False   True  \n",
       "1     False  False  \n",
       "2     False  False  \n",
       "3     False  False  \n",
       "4     False  False  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "22fddb57-a2fd-4c5d-83bf-e2da0b41b873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'anger',\n",
       " 1: 'anticipation',\n",
       " 2: 'disgust',\n",
       " 3: 'fear',\n",
       " 4: 'joy',\n",
       " 5: 'love',\n",
       " 6: 'optimism',\n",
       " 7: 'pessimism',\n",
       " 8: 'sadness',\n",
       " 9: 'surprise',\n",
       " 10: 'trust'}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name = [label for label in df.columns if label not in ['ID', 'Tweet']]\n",
    "id2label = {idx:label for idx, label in enumerate(label_name)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4f2c9e19-e257-4905-ab1c-d62a91eb2167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_tweet = df.loc[:,[\"Tweet\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f933176b-f1ad-43b0-b5a6-a97d36ae91e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Adnan__786__ @AsYouNotWish Dont worry Indian army is on its ways to dispatch all Terrorists to Hell']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c861f6de-4ab1-4eb2-bb0a-5a56a4ec5e43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.49910658597946167,\n",
       "  0.11445894092321396,\n",
       "  0.5174931883811951,\n",
       "  0.1451595574617386,\n",
       "  0.27547383308410645,\n",
       "  0.0479339063167572,\n",
       "  0.2813677191734314,\n",
       "  0.08886060118675232,\n",
       "  0.22894766926765442,\n",
       "  0.027332641184329987,\n",
       "  0.036866359412670135]]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = predict_fn(text_tweet[0], model_and_tokenizer)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c1d9f5f7-e86a-482e-bc18-24204fa6c2b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def proba_to_label(prediction_proba,id2label,threshold):\n",
    "    prediction_label = []\n",
    "    for index in range(len(prediction_proba)):\n",
    "        if prediction_proba[index] > threshold:\n",
    "            prediction_label.append(id2label[index])\n",
    "            \n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "806a5792-a755-4652-89a7-9b2e86272b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust']\n"
     ]
    }
   ],
   "source": [
    "print(proba_to_label(results[0],id2label,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5e3b9c0e-6cce-4f07-ae2e-26a73c5a8426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  love  optimism  pessimism  \\\n",
       "0      1             1        0     0    0     0         1          0   \n",
       "1      0             0        1     0    0     0         0          0   \n",
       "2      1             0        1     0    0     0         0          0   \n",
       "3      0             0        0     0    1     0         0          0   \n",
       "4      0             0        0     1    0     0         0          0   \n",
       "\n",
       "   sadness  surprise  trust  \n",
       "0        0         0      1  \n",
       "1        0         0      0  \n",
       "2        1         0      0  \n",
       "3        1         0      0  \n",
       "4        1         0      0  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index = df.iloc[:,2:].astype(int)\n",
    "label_index.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2cc29a9a-4a29-48aa-8a72-ca2dd3de3f62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index = label_index.to_numpy()\n",
    "label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f98b94aa-1547-46c4-a3fc-d98abe791c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_proba = np.zeros_like(label_index,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8d264945-80c3-4599-ba2b-b500e46a9d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in range(len(text_tweet)):\n",
    "    result = predict_fn(text_tweet[index], model_and_tokenizer)\n",
    "    result = np.squeeze(np.array(result), axis=0)    \n",
    "    predictions_proba[index,:] = result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976aef1-4380-4de8-8b84-9cff0f17ebdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3eceeaf0-bcba-472d-84df-af443c700a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "930a710f-3823-4909-84be-ca149dbd7ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_label_metrics(labels, predictions_proba, threshold = 0.5):\n",
    "    y_true = labels\n",
    "\n",
    "    predictions = np.zeros_like(labels)\n",
    "    predictions[np.where(predictions_proba >= threshold)] = 1\n",
    "    \n",
    "    y_pred = predictions\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    f1_micro_average = f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    metrics = {'precision': precision,\n",
    "               'recall': recall,\n",
    "               'f1': f1_micro_average}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a1b1013a-7ee3-4a85-b286-77059c34ea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = multi_label_metrics(label_index, predictions_proba, threshold = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f9ebf7d7-3380-453f-b3de-63ee116053ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.4748230950671726,\n",
       " 'recall': 0.5883848011183124,\n",
       " 'f1': 0.5255391600454029}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde73d69-6e1f-4b5b-b51a-fea8b8f0c00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
