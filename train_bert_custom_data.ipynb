{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee062d-5b1a-4999-9105-525ecb44193f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97448ccb-9e3c-4798-a681-95f418adb2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/sem_eval_2018_task_1_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7122d5-1603-4c8f-95c4-0fe19f378501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16472513-d4cc-4560-a0e6-3a4225478d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ab9fe-4805-4034-96dc-47d0c7e4b7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473a485-dfda-4feb-8616-a3c38b838a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_en = df.loc[:,[\"Tweet\"]]\n",
    "data_en.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742db28a-87aa-422d-b9c9-6f23360c32e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_en.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea0e28-cb3c-4dfc-b100-f67bb056b798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a0105-ad1a-4b60-9b70-876f4c87b2a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_index = df.iloc[:,2:].astype(int)\n",
    "label_index.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420dae6c-7525-4af2-8f1c-a6bae3d4721a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_one_hot = label_index.to_numpy()\n",
    "label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537be96-e776-4f6c-b009-f8590b10c6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/training\n",
    "!pip install transformers==4.27.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3af8c-89fb-4c2c-8a6b-43f5d2133943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f274c-8d41-4b3e-9681-64714fded2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc04ca-c24d-4b22-9589-7e1db8719617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyNLPDataset(Dataset):\n",
    "    def __init__(self, file_name, model_name):\n",
    "        # data loading\n",
    "        df = pd.read_csv(file_name)\n",
    "        self.data_en = df.loc[:,[\"Tweet\"]].squeeze().values.tolist()\n",
    "        self.label_index = torch.from_numpy(df.iloc[:,2:].astype(int).to_numpy())\n",
    "        self.n_samples = df.shape[0]\n",
    "        self.embedding_model = None\n",
    "        self.tokenizer = None\n",
    "        self.model_name = model_name\n",
    "        self.tokenized_text = [ {} for i in range(df.shape[0])]\n",
    "        #self.token_type_ids = None\n",
    "        #self.attention_mask = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.tokenized_text[index] == {}:\n",
    "            if self.tokenizer == None:\n",
    "                self.load_embedding_model()\n",
    "            \n",
    "            text = self.data_en[index]\n",
    "            assert isinstance(text, str)\n",
    "            text_tokenized = self.tokenize_function(text)\n",
    "            self.tokenized_text[index] = text_tokenized\n",
    "        #return self.tokenized_text[index]\n",
    "        return self.tokenized_text[index], self.label_index[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def load_embedding_model(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
    "    \n",
    "    def tokenize_function(self,text):\n",
    "        # generate token from dataset \n",
    "        tokenized_text = self.tokenizer(text, max_length = 128, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        tokenized_text['input_ids'] = torch.squeeze(tokenized_text['input_ids'])\n",
    "        tokenized_text['token_type_ids'] = torch.squeeze(tokenized_text['token_type_ids'])\n",
    "        tokenized_text['attention_mask'] = torch.squeeze(tokenized_text['attention_mask'])\n",
    "        \n",
    "        return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691ae84-585a-42e0-bd14-22221d3b89ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = MyNLPDataset(\"./dataset/sem_eval_2018_task_1_train.csv\", \"bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e456a-e518-44ca-8502-e326dd755c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#text = \"Hello Serena\"\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "#tokenized_text = tokenizer(text, max_length = 128, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82029db-ccb9-46d4-8007-3fb746e847d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1249603-9471-4733-ad86-bddad1626b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dataset = MyNLPDataset(\"./dataset/sem_eval_2018_task_1_validation.csv\", \"bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49165b-3e27-4f53-b2d4-0ac662b7d221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_count = len(train_dataset)\n",
    "validation_count = len(validation_dataset)\n",
    "print(training_count, validation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed0afe-7308-47b9-9bbf-8cd3137f4223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc9ca1-f1be-4935-8b3f-72e473ef3c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iter = iter(train_dataloader)\n",
    "inputs, labels = next(data_iter)\n",
    "labels = labels.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daf945-d778-4594-ba2c-cd52b6b7e18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920fe55-bb64-42c2-8bff-418548e2b838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd66f7-cf65-4d3c-95fd-a4e5b56afc79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch models inherit from torch.nn.Module\n",
    "class SentenceMultiClassClassifier(nn.Module):\n",
    "    def __init__(self,number_class, pretrained_model):\n",
    "        super(SentenceMultiClassClassifier, self).__init__()\n",
    "        self.number_class = number_class\n",
    "        self.pretrained = BertModel.from_pretrained(pretrained_model)\n",
    "        #self.pretrained = BertModel.from_pretrained(pretrained_model,config=AutoConfig.from_pretrained(pretrained_model, output_attentions=True,output_hidden_states=True))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "        #self.fc1 = nn.Linear(768, 1200)\n",
    "        #self.fc2 = nn.Linear(1200, 1400)\n",
    "        #self.fc3 = nn.Linear(1400, number_class)\n",
    "        \n",
    "        self.linear = nn.Linear(768, number_class)\n",
    "        self.layeroutput = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):            \n",
    "        output_pretrained = self.pretrained(input_ids, token_type_ids, attention_mask)\n",
    "        # Freeze the BERT parameters\n",
    "        #for param in self.pretrained.parameters():\n",
    "        #    param.requires_grad = False\n",
    "            \n",
    "        #x = F.relu(self.fc1(output_pretrained.last_hidden_state[:,0,:].view(-1,768)))\n",
    "        #x = self.dropout(x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        #x = output_pretrained.last_hidden_state[:,0,:].view(-1,768)\n",
    "        \n",
    "        x = output_pretrained.pooler_output\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.layeroutput(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231494b8-fae0-4a82-8a0b-60bc73729a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "# model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# print(inputs)\n",
    "# labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "# pooler_output = model(**inputs).pooler_output\n",
    "# output_hidden = model(**inputs).last_hidden_state[:,0,:].view(-1,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f8177-cfdf-4bc5-8d0a-1f29f0d91da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASS = 11\n",
    "PRETRAINED_MODEL = \"bert-base-multilingual-uncased\"\n",
    "\n",
    "model = SentenceMultiClassClassifier(NUM_CLASS, PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd0a02-55aa-413c-a170-1406febcab2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dd0f6-c286-48dd-9fc7-cd719a5f001d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56eedd-c27e-4ded-9bac-7dfb1adc07fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = labels.type(torch.FloatTensor)\n",
    "labels = labels.to(device)\n",
    "for key, value in inputs.items():\n",
    "    inputs[key] = inputs[key].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277e111-e414-43a7-b0ee-dcaacdb0cdce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f343c4-c2f9-42cf-82fa-b65e9cba29f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935e6d6-d60b-4a92-8970-ed9df452b2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d880ad1-e8d0-4aa9-9566-bb1d2306243c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the loss and its gradients\n",
    "loss = loss_fn(outputs, labels)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8b1cb-eb67-4bf4-ba41-7cb49f9ea821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ca455-24b5-45b2-8a3c-26508fff7c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index,training_loader, optimizer, model, loss_fn, device):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    batch_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = inputs[key].to(device)\n",
    "            \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "           \n",
    "    return batch_loss / len(training_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a4a17-08bd-4b85-b4d5-58ee11673a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_one_epoch(0,train_dataloader, optimizer, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46472bca-d8f1-4d1f-a958-0647ee148b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2f73e-215f-4d8d-8ec1-5d7353d4683c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "EPOCHS = 2\n",
    "epoch_number = 0\n",
    "best_vloss = 1_000_000.\n",
    "MODEL_SAVE_LOCATION = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c6a47-7bd5-43b8-a6c0-9a6b89a01731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, train_dataloader, optimizer, model, loss_fn, device)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    #model.train(False)\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    for i, vdata in enumerate(validation_dataloader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vlabels = vlabels.type(torch.FloatTensor)\n",
    "        vlabels = vlabels.to(device)\n",
    "        for key, value in vinputs.items():\n",
    "            vinputs[key] = vinputs[key].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            voutputs = model(**vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss.item()\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = '{}/model.pth'.format(MODEL_SAVE_LOCATION)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc352d56-ae99-4047-84a5-4411c5c974fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbe987-b035-4a1e-8532-37cc64552231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4d2af-6324-4400-86c9-7062742ea2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7688510-0b93-440f-878a-40188afb029b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./scripts/train_nlp_bert_sm_compatible.py --epochs 20 --model_id \"bert-base-multilingual-uncased\" --training_dir \"./dataset\" --output_dir \"./model\" --train_batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db9d74-00e7-4909-9165-6274f182b892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
